\documentclass[12pt,a4paper]{article}

% 使用中文宏包
\usepackage[UTF8]{ctex}
\usepackage{graphicx} %插入图片的宏包
\usepackage{float} %设置图片浮动位置的宏包
\usepackage{subfigure} %插入多图时用子图显示的宏包
\usepackage{authblk}
\usepackage[strings]{underscore}
\usepackage{times}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{overpic}
\usepackage{listings}
\usepackage{color}
\usepackage{enumitem}
\setenumerate[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setitemize[1]{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}
\setdescription{itemsep=0pt,partopsep=0pt,parsep=\parskip,topsep=5pt}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{ %
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}


\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}


\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\newcommand{\cmm}[1]{\textcolor[rgb]{0,0.6,0}{CMM: #1}}
\newcommand{\todo}[1]{{\textcolor{red}{\bf [#1]}}}
\newcommand{\alert}[1]{\textcolor[rgb]{.6,0,0}{#1}}

\newcommand{\IT}{IT\cite{98pami/Itti}}
\newcommand{\MZ}{MZ\cite{03ACMMM/Ma_Contrast-based}}
\newcommand{\GB}{GB\cite{conf/nips/HarelKP06}}
\newcommand{\SR}{SR\cite{07cvpr/hou_SpectralResidual}}
\newcommand{\FT}{FT\cite{09cvpr/Achanta_FTSaliency}}
\newcommand{\CA}{CA\cite{10cvpr/goferman_context}}
\newcommand{\LC}{LC\cite{06acmmm/ZhaiS_spatiotemporal}}
\newcommand{\AC}{AC\cite{08cvs/achanta_salient}}
\newcommand{\HC}{HC-maps }
\newcommand{\RC}{RC-maps }
\newcommand{\Lab}{$L^*a^*b^*$}
\newcommand{\mypara}[1]{\paragraph{#1.}}

\graphicspath{{figures/}}

\setcounter{page}{1}

\begin{document}


%%%%%%%%% TITLE

\title{论文阅读报告：Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks \cite{cyclegan}}

\author[*]{纳文琪}
\affil[*]{信息学院，学号：22018000164}
\date{}
\maketitle
\section{引言}

\paragraph{} 图像翻译是一种转换图像的表示的过程。大多数传统方法都是针对特定领域的图像翻译问题设计专门的方法来实现图像翻译。生成对抗网络兴起后，大量研究试图构建对任何训练数据都通用的框架来实现图像翻译。然而，这些方法要么生成的图片质量不高，要么需要获取过程困难且昂贵的配对训练数据。本文所阐述的论文提出了一种不需要昂贵的配对数据，同时生成图片的质量也比较高的方法，其被称为CycleGAN。
\section{相关工作}
\paragraph{图像翻译} 图像翻译（image-to-image translation）指的是，在给定充分训练数据的情况下，将图片的一种表示转换成另外一种。虽然这类任务的目的都差不多，仅是训练数据不同，但传统的方法都必须根据特定目标设计专门的方法来完成。
\paragraph{生成对抗网络} 生成对抗网络（Generative Adversarial Networks, GANs）是最近今年的研究热点之一，它在图像生成、图像编辑、表示学习等方面取得了瞩目的成绩。GAN由生成器和判别器两部分组成。生成器用于生成期望的数据（假数据），并尽量让生成的数据骗过判别器。而判别器则负责尽可能准确地识别出哪些是假数据（由生成器生成），哪些是真数据。
\paragraph{} GAN生产的数据可能满足特定的分布，但却是无法控制的，而有条件的生产对抗网络（Conditional Generative Adversarial Networks, cGAN）的出现则解决了GAN无法控制数据的生成这个问题。cGAN通过在生成器和判别器的输入端同时加入标签数据来控制数据的生成和判别。
\paragraph{pix2pix} pix2pix是有Isola等\cite{pix2pix}提出的一个图像翻译系统。它针对图像翻译需要根据不同的训练数据设计专门的方法的问题，提出了一套通用的框架。它将配对数据作为训练集，通过以cGAN为基础设计的模型来实现图像翻译。这个框架适用于任何分布的数据集，只需要能够提供配对训练数据就行。

\section{无配对数据情况下的图像翻译}
\subsection{概述}
\paragraph{} 在计算机视觉领域，已经存在大量的方法可以实现图像翻译。在此论文之前，pix2pix算是其中的佼佼者，但它需要使用配对数据对模型进行训练。然而，获取配对数据常常是及其困难的，且获取的代价也相对昂贵。因此，本文所讲述的论文试图找到一种无须配对训练数据的图像翻译方法。论文构建了这样一个系统：在仅有非配对训练数据的情况下，学习一组图片的特征，并能够将这些特征应用到另外一组图片上，使后者成为与前者同一类型的图片。例如，通过学习一组斑马的图片，将一张图片上的马转换为斑马。
\paragraph{} 为了达到上述目的，一般需要构建一个映射函数（生成器）$G: X \rightarrow Y$，其输出$ \hat y = G(x), x \in X $，且 $\hat y \approx y, y \in Y$。也就是说，G的输出$\hat y$要能骗过判别器。然而，在构建生成器的时候，常常遇到的模型坍塌的问题。当存在一个$\hat y \approx y$时，生成器最安全的做法就是将任意的输入$x$都映射到这个$\hat y$。
\paragraph{} 文章提出用“循环连续性”来处理模型坍塌的问题。在构建生成器$G: X \rightarrow Y$的同时，构建另外一个生成器$F: Y \rightarrow X$。如果有$\hat y = G(x) \approx y$时，应当同时有 $\hat x = F(\hat y) \approx x$，即$F(G(x)) \approx \hat x$。通过最小化“循环一致性损失”优化生成器G和F。

\subsection{方法}
\paragraph{模型} 文章通过给定两个集合：${\left \{x_i \right \}}^N_{i=1}$和${\left \{y_j \right \}}^M_{i=j}$，来构建两个生成器：$ \hat y = G(x), x \in X $和$ \hat y = G(x), x \in X $。与此相对应，还需要构建两个判别器：$D_X$和$D_Y$，分别用于对$x$与$\hat x$以及$y$与$\hat y$做判别。
\paragraph{损失函数} 本文模型的损失函数由两部分组成：对抗损失和循环一致性损失。
	\subparagraph{} 对抗损失函数有两个，分别对应生成器$G$和判别器$D_Y$，以及生成器$F$和判别器$D_X$。具体表示为：
	\begin{equation}
		\mathfrak{L}_{GAN}(G, D_Y, X, Y) = \mathbb{E}_{y \sim p_{data}(y)}[\log D_Y(y)] + \mathbb{E}_{x \sim p_{data}(x)}[\log(1 - D_Y(G(x)))]
	\end{equation}
	\begin{equation}
		\mathfrak{L}_{GAN}(F, D_X, Y, X) = \mathbb{E}_{x \sim p_{data}(x)}[\log D_X(x)] + \mathbb{E}_{y \sim p_{data}(y)}[\log(1 - D_X(F(y)))]
	\end{equation}
	\subparagraph{} 文章将循环一致性分为两个部分：输入为$x$的过程$x \rightarrow G(x) \rightarrow F(G(x)) \rightarrow \hat x$，这称为前向循环一致性，以及输入为$y$的过程$y \rightarrow F(y) \rightarrow G(F(y)) \rightarrow \hat y$，这称为后向循环一致性。这两种一致性组合就得到循环一致性损失：
	\begin{equation}
		\mathfrak{L}_{cyc}(G, F) = E_{x \sim p_{data}(x)}[\left \| F(G(x)) - x \right \|_1] + E_{y \sim p_{data}(y)}[\left \| G(F(y)) - y \right \|_1]
	\end{equation}
	\subparagraph{} 模型总的损失函数就是：
	\begin{equation}
		\mathfrak{L}(G,F,D_X,D_Y)=\mathfrak{L}_{GAN}(G, D_Y, X, Y)+\mathfrak{L}_{GAN}(F, D_X, Y, X)+\lambda\mathfrak{L}_{cyc}(G, F)
	\end{equation}
	其中$\lambda$是一个超参数，表示循环一致性损失的影响系数。
	
\subsection{实现}
	\subsubsection{网络架构}
	\paragraph{生成器网络} 文章采用“卷积-残差-微步卷积”\cite{johnson2016perceptual}的结构来构造生成器。与一般的GAN不同的是，此处的生成器输入的是$X$集合中的元素，即一张图片，而不是随机噪声。生成器网络首先对图片进行两次步长为2的卷积操作，其输出的结果再经过一组残差块，最后的结果再进行两次步长为$\frac{1}{2}$的微步卷积，最终得到输入的图片。
	\paragraph{判别器网络} 对于判别器网络，文章使用$70 \times 70$的PatchGAN来实现，将输入分割成很小的部分分别进行判别。这样的网络产生的参数更少，而且适用于任意尺寸的输入图片。
	
	\subsubsection{训练}
	\paragraph{} 训练的不稳定性是GAN总所周知的一个问题。文章采用两种技术来稳定模型的训练。首先，文章采用LSGAN来替代常规的GAN的损失函数，这在稳定训练过程的同时还能够提供训练的质量。其次，为避免模型抖动，训练判别器时，不单单使用刚刚生成的图片，而是连同之前生成的图片一起进行训练。
	
\subsection{实验结果}
\paragraph{} 文章将CycleGAN与CoGAN、Pixel+GAN、Feature loss+GAN、BiGAN、pix2pix进行了比较。文章首先进行了几个系统之间的“真假”检验实验，通过将系统生成的图片以众包（Amazon Mechanical Turk, AMT）的方式分发给真人，并让其判断是否是真实图片的方式，来评估系统的能力。经过对比，在“Map $\rightarrow$ Photo”实验中，CycleGAN生成的图片有超过26\%的被标记为真，远远超过第二名的2\%。文章之后还做了Cityscapes数据集上的“Photo $\rightarrow$ Label”实验和“Label $\rightarrow$ Photo”实验，都取得了最好的成绩。

\subsection{应用}
\paragraph{} CycleGAN现在已经被用在了多个应用领域中，包括：
\begin{itemize}
	\item{物体转换} 在两类相似的物品之间进行转换，例如，将苹果转换成桔子。
	\item{四季转换} 将冬天和夏天的风景图片进行转换。
	\item{画册风格转换} 将一组图片的风格转换为另外一组图片的风格。转换模仿的是一组图片（例如梵高）的风格，而不是一张图片（例如《星空》）的风格。
	\item{由油画生成照片}
	\item{照片增强} 将景深较深的照片转换成景深较浅的照片。
\end{itemize}

\subsection{局限和结论}
\paragraph{} 虽然本文的方法取得了一些成就，但离完美还很远。这个方法针对颜色和纹理的转换效果不错，但如果存在几何形状上的转换，效果就不太好。还有些失败则是由训练图片的特征分布所决定的。例如，人骑着马的图片转换成斑马时就会失败，那是因为训练集中所有的马都没有人骑着。
\paragraph{} 本文的方法已经在很多方面展开了应用，本文也扩展了此类方法在“无监督”学习方面的边界。
















\bibliographystyle{ieeepes}
\bibliography{../Saliency}
\end{document}



























































